"""Example config for the batch experiment.

Such an experiment corresponds to what we would normally think of as a "single
experiment" in a research project. It can contain multiple runs (e.g. a grid search).

We use here a following naming convention:
- experiments by John Doe go into the `experiments/jd` directory,
- the experiment name is `jd_<NUMBER>_<SHORT_DESCRIPTION>`, where `NUMBER` is manually
increased; prepend with zeros to keep the order in the file system,
- we commit experiments to the repository. Once committed, the experiment should not be
modified under normal circumstances. This way we maintain a history of experiments.
"""

import os

from AmongUs.configs import RunConfig, TrainingConfig
from AmongUs.utils.batch_jobs import create_cluster_run_configs, run_multiple, ClusterOptions

# Experiment name is derived from the file name.
# It is then used to set up wandb/k8s names.
experiment_name = os.path.basename(__file__).replace(".py", "")

# We define a base config which is the starting point for the grid search.
base_config = RunConfig(
    experiment_name=experiment_name,
    training=TrainingConfig(num_epochs=3),
)

LEARNING_RATES = [1e-4, 1e-3, 1e-2]
BATCH_SIZES = [16, 32]
# Fraction of a node needed for a single run. Can be specified separately for each run,
# e.g. if we define runs with different resource requirements within one experiment.
NODE_FRAC_NEEDED = 0.5
# Sequence of tuples (override_args, node_frac_needed) for each run; the override_args
# are merged with the base config.
override_args_and_node_frac_needed = [
    (
        {
            "training.learning_rate": learning_rate,
            "training.batch_size": batch_size,
        },
        NODE_FRAC_NEEDED,
    )
    for learning_rate in LEARNING_RATES
    for batch_size in BATCH_SIZES
]

cluster_options = ClusterOptions(
    CPU=4,
    MEMORY="20G",
    GPU=1,
)

if __name__ == "__main__":
    run_configs = create_cluster_run_configs(
        base_config, override_args_and_node_frac_needed
    )
    # Submit runs to the cluster (command-line lets you --dry-run or print them)
    run_multiple_cli(run_configs, cluster_options)
